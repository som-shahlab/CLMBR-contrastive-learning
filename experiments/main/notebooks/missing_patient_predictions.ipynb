{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Cohort, get train/val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cohort_dir = \"/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/data/cohort\"\n",
    "\n",
    "# load cohort\n",
    "df_cohort = pd.read_parquet(\n",
    "    os.path.join(\n",
    "        cohort_dir,\n",
    "        \"cohort_split.parquet\",\n",
    "    ),\n",
    "    engine='pyarrow'\n",
    ")\n",
    "\n",
    "# datetime -> date\n",
    "df_cohort = df_cohort.assign(date = pd.to_datetime(df_cohort['admit_date']).dt.date)\n",
    "\n",
    "# get train/val sets\n",
    "train = df_cohort.query(\n",
    "    f\"hospital_mortality_fold_id!=['val','test','ignore'] and admission_year==[2008,2009,2010,2011,2012,2013,2014,2015,2016]\"\n",
    ")\n",
    "    \n",
    "val = df_cohort.query(\n",
    "    f\"hospital_mortality_fold_id==['val'] and admission_year==[2008,2009,2010,2011,2012,2013,2014,2015,2016]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert and save person IDs for CLMBR info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/data/labelled_data/hospital_mortality/pretrained/gru_sz_800_do_0.1_cd_0_dd_0_lr_0.001_l2_0.01'\n",
    "extracts_dir = \"/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/data/extracts/20210723\"\n",
    "clmbr_model_path = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/artifacts/models/clmbr/pretrained/models/gru_sz_800_do_0.1_cd_0_dd_0_lr_0.001_l2_0.01'\n",
    "model_debug_path = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/debug/logging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lists of patient info for hospital_mortality task\n",
    "train_pids = pd.read_csv(f'{data_path}/ehr_ml_patient_ids_train.csv').to_numpy().flatten()\n",
    "val_pids = pd.read_csv(f'{data_path}/ehr_ml_patient_ids_val.csv').to_numpy().flatten()\n",
    "\n",
    "train_days = pd.read_csv(f'{data_path}/day_indices_train.csv').to_numpy().flatten()\n",
    "val_days = pd.read_csv(f'{data_path}/day_indices_val.csv').to_numpy().flatten()\n",
    "\n",
    "train_labels = pd.read_csv(f'{data_path}/labels_train.csv').to_numpy().flatten()\n",
    "val_labels = pd.read_csv(f'{data_path}/labels_val.csv').to_numpy().flatten()\n",
    "\n",
    "train_data = (train_labels,train_pids,train_days)\n",
    "val_data = (val_labels,val_pids,val_days)\n",
    "\n",
    "# before creating dataset length of pids matches length of labels\n",
    "assert(len(train_labels) == len(train_pids)==len(train_days))\n",
    "assert(len(val_labels) == len(val_pids)==len(val_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Patient Timeline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehr_ml.clmbr import PatientTimelineDataset\n",
    "\n",
    "# generate dataset\n",
    "dataset = PatientTimelineDataset(\n",
    "    os.path.join(extracts_dir, \"extract.db\"), \n",
    "    os.path.join(extracts_dir, \"ontology.db\"),\n",
    "    os.path.join(clmbr_model_path, \"info.json\"),\n",
    "    train_data,\n",
    "    val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End-to-end Binary Classification Model with CLMBR as Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ehr_ml.clmbr.rnn_model import PatientRNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BinaryLinearCLMBRClassifier(nn.Module):\n",
    "            \n",
    "    def __init__(self, model, device=None):\n",
    "        super().__init__()\n",
    "        self.config = model.config\n",
    "        self.timeline_model = model.timeline_model\n",
    "        self.linear = nn.Linear(model.config[\"size\"], 1)\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.criterion = nn.Sigmoid()\n",
    "        self=self.to(self.device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        outputs = dict()\n",
    "        \n",
    "        embedding = self.timeline_model(batch[\"rnn\"])\n",
    "\n",
    "        label_indices, label_values = batch[\"label\"]\n",
    "\n",
    "        flat_embeddings = embedding.view((-1, embedding.shape[-1]))\n",
    "        \n",
    "        target_embeddings = F.embedding(label_indices, flat_embeddings) \n",
    "        \n",
    "        logits = self.linear(target_embeddings).flatten()\n",
    "        \n",
    "        outputs['pids']=batch['pid']\n",
    "        outputs['pred_probs'] = self.criterion(logits)\n",
    "        outputs['labels'] = label_values\n",
    "        outputs['loss'] = F.binary_cross_entropy_with_logits(\n",
    "            logits, label_values.float(), reduction=\"sum\"\n",
    "        )\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        \n",
    "        self.eval()\n",
    "        \n",
    "        pred_probs = []\n",
    "        labels = []\n",
    "        pids = []\n",
    "        mismatch_pids = []\n",
    "        pbar = tqdm(total=dataloader.num_batches)\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                if len(batch['pid']) != len(batch['label']):\n",
    "                    mismatch_pids.extend(batch['pid'])\n",
    "                outputs = self.forward(batch)\n",
    "                pred_probs.extend(list(outputs['pred_probs'].cpu().numpy()))\n",
    "                labels.extend(outputs['labels'].cpu().numpy())\n",
    "                pids.extend(outputs['pids'])\n",
    "                pbar.update(1)\n",
    "                \n",
    "        return {\n",
    "            'pid': pids,\n",
    "            'labels': labels,\n",
    "            'pred_probs': pred_probs,\n",
    "            'mismatch_pids': mismatch_pids,\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def load_weights(self,model_dir):\n",
    "        \n",
    "        model_data = torch.load(\n",
    "            os.path.join(model_dir,\"best\")\n",
    "        )\n",
    "        \n",
    "        self.load_state_dict(model_data)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Model Config and Load CLMBR info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehr_ml.clmbr.utils import read_info\n",
    "import ehr_ml\n",
    "import json\n",
    "\n",
    "model_dir = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/artifacts/models/clmbr/pretrained/models/gru_sz_800_do_0.1_cd_0_dd_0_lr_0.001_l2_0.01'\n",
    "\n",
    "clmbr_model = ehr_ml.clmbr.CLMBR.from_pretrained(clmbr_model_path, 'cuda:0').to('cuda:0')\n",
    "clmbr_model.config['model_dir'] = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/debug/model'\n",
    "clmbr_model.config['epochs_per_cycle'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = BinaryLinearCLMBRClassifier(clmbr_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 18:09:25,456 Args: {'batch_size': 2000, 'eval_batch_size': 2000, 'num_first': 9262, 'num_second': 10044, 'size': 800, 'lr': 0.001, 'dropout': 0.1, 'encoder_type': 'gru', 'rnn_layers': 1, 'tied_weights': True, 'l2': 0.01, 'b1': 0.9, 'b2': 0.999, 'e': 1e-08, 'epochs_per_cycle': 5, 'warmup_epochs': 2, 'code_dropout': 0.0, 'day_dropout': 0.0, 'model_dir': '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/debug/model'}\n",
      "2022-04-05 18:09:25,460 Batches per epoch = 1124\n",
      "2022-04-05 18:09:25,461 Total batches = 5620\n",
      "2022-04-05 18:09:25,462 Start training\n",
      "2022-04-05 18:09:25,462 About to start epoch 0\n",
      "/local-scratch/nigam/envs/jlemmon/debug/lib/python3.9/site-packages/ehr_ml/clmbr/opt.py:115: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
      "2022-04-05 18:09:25,751 Seen batch 0\n",
      "2022-04-05 18:10:48,601 Epoch 0 is complete\n",
      "2022-04-05 18:11:39,404 Train loss: 2.463252172335982\n",
      "2022-04-05 18:11:39,407 Val loss: 0.5449642614857294\n",
      "2022-04-05 18:11:39,513 Saving best model to /local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/debug/model/best\n",
      "2022-04-05 18:11:39,514 About to start epoch 1\n",
      "2022-04-05 18:11:39,772 Seen batch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgs: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(model\u001b[38;5;241m.\u001b[39mconfig))\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local-scratch/nigam/envs/jlemmon/debug/lib/python3.9/site-packages/ehr_ml/clmbr/trainer.py:111\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, dataset, use_pbar)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/local-scratch/nigam/envs/jlemmon/debug/lib/python3.9/site-packages/ehr_ml/clmbr/trainer.py:73\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, dataset, pbar)\u001b[0m\n\u001b[1;32m     70\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 73\u001b[0m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n",
      "File \u001b[0;32m/local-scratch/nigam/envs/jlemmon/debug/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local-scratch/nigam/envs/jlemmon/debug/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # have trained model saved, can skip this cell\n",
    "from ehr_ml.clmbr import Trainer\n",
    "from ehr_ml.utils import set_up_logging\n",
    "import logging\n",
    "\n",
    "set_up_logging(os.path.join(model_debug_path,'train.log'))\n",
    "logging.info(\"Args: %s\", str(model.config))\n",
    "trainer = Trainer(model)\n",
    "trainer.train(dataset, use_pbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_weights(model.config['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct dataloader for validation set to get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehr_ml.clmbr.dataset import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, threshold = model.config['num_first'], is_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [00:08, 29.12it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict(dataloader)\n",
    "assert(len(outputs['pid'])==len(outputs['labels'])==len(outputs['pred_probs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18867, 18867, 18867)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different lengths of pids vs. labels & pred_probs\n",
    "# seems to only happen to 31 pids\n",
    "len(outputs['pid']), len(outputs['labels']), len(outputs['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date for day ID: 2011-03-14 patient's admission date: 2011-03-14 23:00:00\n",
      "date for day ID: 2016-03-13 patient's admission date: 2016-03-13 16:42:00\n",
      "date for day ID: 2016-08-03 patient's admission date: 2016-08-03 07:52:00\n",
      "date for day ID: 2014-11-24 patient's admission date: 2014-11-24 13:38:00\n",
      "date for day ID: 2016-07-28 patient's admission date: 2016-07-28 21:24:00\n",
      "date for day ID: 2013-04-04 patient's admission date: 2013-04-04 23:52:00\n",
      "date for day ID: 2008-01-22 patient's admission date: 2008-01-22 12:20:00\n"
     ]
    }
   ],
   "source": [
    "from ehr_ml import timeline\n",
    "\n",
    "timelines = timeline.TimelineReader(os.path.join(extracts_dir, \"extract.db\"))\n",
    "\n",
    "# In my main script I've tried printing the pid list for a batch if a mismatch was found\n",
    "# example pids from last batch of validation, one of these pids has no prediction/label\n",
    "# can't tell which one is the problem pid, all the pids seem to be within my validation range (2008-01-01 to 2016-12-31)\n",
    "# not sure why the dataloader/dataset is not loading the timeline/labels for these pids\n",
    "for pid in [2574937, 2163575, 1216845, 162573, 1985692, 1389474, 1023077]:\n",
    "    patient = timelines.get_patient(pid)\n",
    "    print(\n",
    "        \"date for day ID:\",\n",
    "        patient.days[\n",
    "            val_days[\n",
    "                np.where(val_pids==pid)[0][0]\n",
    "            ]\n",
    "        ].date,\n",
    "        \"patient's admission date:\", \n",
    "        val.iloc[np.where(val_pids==pid)[0][0]]['admit_date']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960986464846224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score as auc\n",
    "auc(outputs['labels'], outputs['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debug",
   "language": "python",
   "name": "debug"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ehr_ml.clmbr import Trainer\n",
    "from ehr_ml.clmbr import PatientTimelineDataset\n",
    "from ehr_ml.clmbr.dataset import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tasks = ['hospital_mortality', 'LOS_7', 'icu_admission', 'readmission_30', 'bladder_cancer', 'breast_cancer',  'renal_cancer', 'diabetic_ketoacidosis', 'edema', 'hyperkylemia', 'revascularization','stroke', 'sudden_cardiac_death', 'acute_renal_failure', 'acute_myocardial_infarction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(task):\n",
    "    \"\"\"\n",
    "    Load datasets from split csv files.\n",
    "    \"\"\"\n",
    "    data_path = f'/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/data/labelled_data/{task}/pretrained/gru_sz_800_do_0.1_cd_0_dd_0_lr_0.001_l2_0.01'\n",
    "\n",
    "    train_pids = pd.read_csv(f'{data_path}/ehr_ml_patient_ids_train.csv')\n",
    "    val_pids = pd.read_csv(f'{data_path}/ehr_ml_patient_ids_val.csv')\n",
    "    test_pids = pd.read_csv(f'{data_path}/ehr_ml_patient_ids_test.csv')\n",
    "\n",
    "    train_days = pd.read_csv(f'{data_path}/day_indices_train.csv')\n",
    "    val_days = pd.read_csv(f'{data_path}/day_indices_val.csv')\n",
    "    test_days = pd.read_csv(f'{data_path}/day_indices_test.csv')\n",
    "\n",
    "    train_labels = pd.read_csv(f'{data_path}/labels_train.csv')\n",
    "    val_labels = pd.read_csv(f'{data_path}/labels_val.csv')\n",
    "    test_labels = pd.read_csv(f'{data_path}/labels_test.csv')\n",
    "\n",
    "    print('Prevelance')\n",
    "    train_data = (train_labels.to_numpy().flatten(),train_pids.to_numpy().flatten(),train_days.to_numpy().flatten())\n",
    "    print(task, 'train', '{0:.3f}'.format(np.sum(train_labels)[0]/len(train_labels)*100))\n",
    "    val_data = (val_labels.to_numpy().flatten(),val_pids.to_numpy().flatten(),val_days.to_numpy().flatten())\n",
    "    print(task, 'val', '{0:.3f}'.format(np.sum(val_labels)[0]/len(val_labels)*100))\n",
    "    test_data = (test_labels.to_numpy().flatten(),test_pids.to_numpy().flatten(),test_days.to_numpy().flatten())\n",
    "    print(task, 'test', '{0:.3f}'.format(np.sum(test_labels)[0]/len(test_labels)*100))\n",
    "\n",
    "#     train_dataset = PatientTimelineDataset(args.extract_path + '/extract.db', \n",
    "#                                              args.extract_path + '/ontology.db', \n",
    "#                                              f'{clmbr_model_path}/info.json', \n",
    "#                                              train_data, \n",
    "#                                              val_data )\n",
    "\n",
    "#     test_dataset = PatientTimelineDataset(args.extract_path + '/extract.db', \n",
    "#                                          args.extract_path + '/ontology.db', \n",
    "#                                          f'{clmbr_model_path}/info.json', \n",
    "#                                          train_data, \n",
    "#                                          test_data )\n",
    "\n",
    "#     return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevelance\n",
      "hospital_mortality train 2.241\n",
      "hospital_mortality val 2.125\n",
      "hospital_mortality test 1.906\n",
      "Prevelance\n",
      "LOS_7 train 20.458\n",
      "LOS_7 val 20.459\n",
      "LOS_7 test 18.942\n",
      "Prevelance\n",
      "icu_admission train 2.264\n",
      "icu_admission val 2.145\n",
      "icu_admission test 4.269\n",
      "Prevelance\n",
      "readmission_30 train 5.331\n",
      "readmission_30 val 5.092\n",
      "readmission_30 test 4.819\n",
      "Prevelance\n",
      "bladder_cancer train 0.649\n",
      "bladder_cancer val 0.610\n",
      "bladder_cancer test 0.922\n",
      "Prevelance\n",
      "breast_cancer train 2.267\n",
      "breast_cancer val 2.353\n",
      "breast_cancer test 2.488\n",
      "Prevelance\n",
      "renal_cancer train 0.801\n",
      "renal_cancer val 0.694\n",
      "renal_cancer test 1.081\n",
      "Prevelance\n",
      "diabetic_ketoacidosis train 0.397\n",
      "diabetic_ketoacidosis val 0.519\n",
      "diabetic_ketoacidosis test 0.665\n",
      "Prevelance\n",
      "edema train 20.963\n",
      "edema val 20.480\n",
      "edema test 18.991\n",
      "Prevelance\n",
      "hyperkylemia train 15.468\n",
      "hyperkylemia val 15.514\n",
      "hyperkylemia test 13.169\n",
      "Prevelance\n",
      "revascularization train 1.308\n",
      "revascularization val 1.320\n",
      "revascularization test 1.379\n",
      "Prevelance\n",
      "stroke train 7.301\n",
      "stroke val 7.023\n",
      "stroke test 5.046\n",
      "Prevelance\n",
      "sudden_cardiac_death train 1.375\n",
      "sudden_cardiac_death val 1.511\n",
      "sudden_cardiac_death test 1.275\n",
      "Prevelance\n",
      "acute_renal_failure train 13.332\n",
      "acute_renal_failure val 13.007\n",
      "acute_renal_failure test 15.304\n",
      "Prevelance\n",
      "acute_myocardial_infarction train 3.369\n",
      "acute_myocardial_infarction val 3.376\n",
      "acute_myocardial_infarction test 3.909\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    load_datasets(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path ='/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/data/extracts/20210723'\n",
    "model_path = '/local-scratch/nigam/projects/jlemmon/cl-clmbr/experiments/main/artifacts/models/clmbr/pretrained/models/gru_sz_800_do_0.1_lr_0.01_l2_0.01'\n",
    "dataset = PatientTimelineDataset(extract_path + '/extract.db', \n",
    "                                 extract_path + '/ontology.db', \n",
    "                                 f'{model_path}/info.json', \n",
    "                                 train_data, \n",
    "                                 val_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, 7860, is_val=False, batch_size=512, seed=44, device='cuda:4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(sum([len(x) for x in batch['day_index']]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conl",
   "language": "python",
   "name": "conl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
